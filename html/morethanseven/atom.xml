<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Morethanseven]]></title>
  <link href="http://www.morethanseven.net/atom.xml" rel="self"/>
  <link href="http://www.morethanseven.net/"/>
  <updated>2014-01-02T18:08:37+00:00</updated>
  <id>http://www.morethanseven.net/</id>
  <author>
    <name><![CDATA[Gareth Rushgrove]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Testing Packer created images with serverspec]]></title>
    <link href="http://www.morethanseven.net/2014/01/01/testing-packer-created-images-with-serverspec/"/>
    <updated>2014-01-01T15:24:00+00:00</updated>
    <id>http://www.morethanseven.net/2014/01/01/testing-packer-created-images-with-serverspec</id>
    <content type="html"><![CDATA[<p><a href="http://www.packer.io/">Packer</a> provides a great way of describing the steps for creating a virtual machine image. But it doesn&#8217;t have a built-in way of verifying those images.</p>

<p><a href="http://serverspec.org/">Serverspec</a> provides a nice framework for writing tests against infrastructure, asserting the operation of services or the installation of packages.</p>

<p>I&#8217;m interested at the moment in building continous delivery pipelines for infrastructure components and have a simple working example of <a href="https://github.com/garethr/packer-serverspec-example">testing Packer with Serverspec</a> on
Github. The example uses the AWS builder and the Puppet provisioner but the approach should work with other combinations.</p>

<p>This doesn&#8217;t represent a complete infrastructure pipeline, but it does demonstrate an approach to automating one particular component - building base images.</p>

<h2>Testing</h2>

<p>In our example I&#8217;m using the <a href="https://github.com/puppetlabs/puppetlabs-ntp">Puppetlabs NTP</a> module to install and configure NTP. Once the Puppet provisioner has run, but before we build the AMI (or other virtal machine image) we run a test suite. For our example the tests are pretty simple:</p>

<pre><code>describe package('ntp') do
  it { should be_installed }
end

describe service('ntp') do
  it { should be_enabled   }
  it { should be_running   }
end
</code></pre>

<p>If the tests fail, Packer will stop and the AMI won&#8217;t be built. The combination of storing the code (Packer template) alongside a test suite (Serverspec) and building a new AMI whenever you change the code, makes this setup perfect for continuous integration.</p>

<h2>Wercker builds</h2>

<p>As an example of a continuous integration setup the repository contains a <a href="https://github.com/garethr/packer-serverspec-example/blob/master/wercker.yml">wercker.yml</a> configuration file for the excellent <a href="http://devcenter.wercker.com/">Wercker</a> service. Wercker makes setting up multi-step built pipelines easy and nicely configurable via a simple text file in your repository.</p>

<p>The Wercker <a href="https://app.wercker.com/#applications/52c450e489daaf145f001ad8">build for this project is public</a>. Currently the build involves downloading Packer, running <code>packer validate</code> to check the template and eventually running <code>packer build</code> to boot an instance and run our serverspec tests.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Making the web secure, one unit test at a time]]></title>
    <link href="http://www.morethanseven.net/2013/12/29/making-the-web-secure/"/>
    <updated>2013-12-29T14:28:00+00:00</updated>
    <id>http://www.morethanseven.net/2013/12/29/making-the-web-secure</id>
    <content type="html"><![CDATA[<p><em>Originally written as part of <a href="http://sysadvent.blogspot.co.uk/2013/12/day-21-making-web-secure-one-unit-test.html">Sysadvent 2013</a>.</em></p>

<p>Writing automated tests for your code is one of those things that,
once you have gotten into it, you never want to see code without tests
ever again. Why write pages and pages of documentation about how
something should work when you can write tests to show exactly how something does work? Looking at the number and quality of testing tools and frameworks (like cucumber,
rspec, <a href="https://github.com/test-kitchen/test-kitchen">Test Kitchen</a>,
<a href="http://serverspec.org/">Server Spec</a>,
<a href="https://github.com/puppetlabs/beaker">Beaker</a>,
<a href="http://casperjs.org/">Casper</a> and
<a href="http://pivotal.github.io/jasmine/">Jasmine</a> to name a few) that have
popped up in the last year or so I&#8217;m obviously not the only person who
has a thing for testing utilities.</p>

<p>One of the other things I am interested in is web application
security, so this post is all about using the tools and techniques
from unit testing to avoid common web application security issues. I&#8217;m
using Ruby in the examples but you could quickly convert these to other languages if you desire.</p>

<h2>Any port in a storm</h2>

<p>Lets start out with something simple. Accidentally exposing
applications on TCP ports can lead to data loss or introduce a vector
for attack. Maybe your main website is super secure, but you left the
port for your database open to the internet. It&#8217;s the server configuration equivalent of forgetting to lock the back door.</p>

<p>Nmap is a tool lots of people will be familiar with for spanning for
open ports. As well as a command line interface Nmap also has good
library support in lots of languages so lets try and write a simple
tests suite around it.</p>

<pre><code>require "tempfile"
require "nmap/program"
require "nmap/xml"

describe "the scanme.nmap.org website" do
  file = Tempfile.new("nmap.xml")
  before(:all) do
    Nmap::Program.scan do |nmap|
      nmap.xml = file.path
      nmap.targets = "scanme.nmap.org"
    end
  end

  @open_ports = []
  Nmap::XML.new("scan.xml") do |xml|
    xml.each_host do |host|
      host.each_port do |port|
        @open_ports &lt;&lt; port.number if port.state == :open
      end
    end
  end
end
</code></pre>

<p>With the above code in place we can then write tests like:</p>

<pre><code>it "should have two ports open" do
 @open_ports.should have(2).items
end

it "should have port 80 open" do
 @open_ports.should include(80)
end

it "should have port 22 closed" do
 @open_ports.should_not include(22)
end
</code></pre>

<p>We can run these manually, but also potentially as part of a
continuous integration build or constantly as part of a monitoring
suite.</p>

<h2>Run the Guantlt</h2>

<p>We had to do quite a bit of work wrapping Nmap before we could write
the tests above. Wouldn&#8217;t it be nice if someone had already wrapped
lots of useful security minded tools for us? <a href="http://gauntlt.org/">Gauntlt</a> is pretty much just that, it&#8217;s a security testing framework based on cucumber which currently supports curl, nmap, sslyze, sqlmap, garmr and a bunch more tools in master. Lets do something more advanced than our port scanning test above by testing a URL for a SQL injection vulnerability.</p>

<pre><code>@slow
Feature: Run sqlmap against a target
  Scenario: Identify SQL injection vulnerabilities
    Given "sqlmap" is installed
    And the following profile:
      | name       | value                                      |
      | target_url | http://localhost/sql-injection?number_id=1 |
    When I launch a "sqlmap" attack with:
      """
      python &lt;sqlmap_path&gt; -u &lt;target_url&gt; —dbms sqlite —batch -v 0 —tables
      """
    Then the output should contain:
      """
      sqlmap identified the following injection points
      """
    And the output should contain:
      """
      [2 tables]
      +-----------------+
      | numbers         |
      | sqlite_sequence |
      +-----------------+
      """
</code></pre>

<p>The Gauntlt team publish <a href="https://github.com/gauntlt/gauntlt/tree/master/examples">lots of examples</a> like this one alongside the source code, so getting started is easy. Gauntlt is very powerful, but as you&#8217;ll see from the example above you need to know quite a bit about the underlying tools it is using. In the case above you need to know the various arguments to sqlmap and also how to interpret the output.</p>

<h2>Enter Prodder</h2>

<p><a href="https://github.com/garethr/prodder">Prodder</a> is a tool I put together
to automate a few specific types of security testing. In many ways
it&#8217;s very similar to Gauntlt; it uses the cucumber testing framework
and uses some of the same tools (like nmap and sslyze) under the hood.
However rather than a general purpose security framework like Gauntlt,
Prodder is higher level and very opinionated. Here&#8217;s an example:</p>

<pre><code>Feature: SSL
  In order to ensure secure connections
  I want to check the SSL configuration of my servers
  Background:
    Given "sslyze.py" is installed
    Scenario: Check SSLv2 is disabled
      When we test using the "sslv2" protocol
      Then the exit status should be 0
      And the output should contain "SSLv2 disabled"

    Scenario: Check certificate is trusted
      When we check the certificate
      Then the output should contain "Certificate is Trusted"
      And the output should match /OK — (Common|Subject
</code></pre>

<p>Alternative) Name Matches/</p>

<pre><code>      And the output should not contain "Signature Algorithm: md5"
      And the output should not contain "Signature Algorithm: md2"
      And the output should contain "Key Size: 2048"

    Scenario: Check certificate renegotiations
      When we test certificate renegotiation
      Then the output should contain "Client-initiated
</code></pre>

<p>Renegotiations: Rejected&#8221;</p>

<pre><code>      And the output should contain "Secure Renegotiation: Supported"

    Scenario: Check SSLv3 is not using weak ciphers
      When we test using the "sslv3" protocol
      Then the output should not contain "Anon"
      And the output should not contain "96bits"
      And the output should not contain "40bits"
      And the output should not contain " 0bits"
</code></pre>

<p>This is a little higher level than the Gauntlt example — it&#8217;s not
exposing the workings of sslyze that is doing the actual testing. All
you need is an understanding of SSL certifcates. Even if you&#8217;re not an
expert on SSL you can accept the aforementioned opinions of Prodder
about what good looks like. Prodder currently contains steps and
exampes for port scanning, SSL certificates and security minded HTTP
headers. If you already have a cucumber based test suite (including
one based on Gauntlt) you can reuse the step definitions in that too.</p>

<p>I&#8217;m hoping to build upon Prodder, adding more types of tests and
getting agreement on the included opinions from the wider systems
administration community. By having a default set of shared assertions
about the expected security of out system we can more easily move onto
new projects, safe in the knowledge that a test will fail if someone
messes up our once secure configuration.</p>

<h2>I&#8217;m convinced, what should I do next?</h2>

<p>As well as trying out some of the above tools and techniques for
yourself I&#8217;d recommend encouraging more security conversations in your
development and operations teams. Here&#8217;s a few  places to start with:</p>

<ul>
<li><a href="http://www.slideshare.net/beehooze/devopsday-london-ben-hughes-security">Ben Hughes from Etsy talking about security culture at Devopsdays London</a></li>
<li><a href="https://speakerdeck.com/garethr/security-monitoring-with-open-source-penetration-testing-tools">A presentation I gave at Velocity about using penetration testing tools for monitoring purposes</a></li>
<li><a href="http://www.slideshare.net/wickett/gauntlt-velocity-eu2013">A workshop, again from Velocity all about getting started with Gauntlt</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Looking into monitoring and logging tools]]></title>
    <link href="http://www.morethanseven.net/2013/10/13/looking-into-monitoring-and-logging-tools/"/>
    <updated>2013-10-13T12:00:00+01:00</updated>
    <id>http://www.morethanseven.net/2013/10/13/looking-into-monitoring-and-logging-tools</id>
    <content type="html"><![CDATA[<p><em>Originally published on <a href="https://medium.com/p/1cbb173faa3a">Medium</a>.</em></p>

<p>We have a bunch of internal mailing lists at <a href="http://digital.cabinetoffice.gov.uk/">work</a>, and on one of them someone asked:</p>

<blockquote><p>we’re looking into monitoring/logging tools…</p></blockquote>

<p>I ended up writing a bit of a long reply which a few people found useful, so I thought I’d repost it here for posterity. I’m sure this will date but I think it’s a reasonable snapshot of the state of open source monitoring tools at the end of 2013.</p>

<p>Simply put, think about four elements and you won’t be far off on the
technical front. Miss one and you’re probably in trouble.</p>

<ul>
<li>logs</li>
<li>metric storage</li>
<li>metric collection</li>
<li>monitoring checks</li>
</ul>


<p>For logs, some combination of syslog at one end and elasticsearch and
<a href="http://www.elasticsearch.org/overview/kibana/">Kibana</a> at the other are probably the state of the open source art at
the moment. The shipping around is more interesting; <a href="http://logstash.net/">Logstash</a> is improving constantly, <a href="http://heka-docs.readthedocs.org/en/latest/">Heka</a> is an similar alternative from Mozilla, and <a href="http://fluentd.org/">Fluentd</a> looks nice too.</p>

<p>For pure metrics it’s all about <a href="http://graphite.wikidot.com/">Graphite</a>, which is both awesome and
perilous. Not much else really competes in the open source world at
present. Maybe <a href="http://opentsdb.net/">OpenTSB</a> (is you’re into a Hadoop stack.)</p>

<p>For collecting metrics on boxes I’d probably look at <a href="http://collectd.org/">collectd</a> or <a href="https://github.com/BrightcoveOS/Diamond">diamond</a> both of which have pros and cons but work well. <a href="https://github.com/etsy/statsd/">Statsd</a> is also useful here for different types of metric collection and aggregation. <a href="http://ganglia.sourceforge.net/">Ganglia</a> is interesting too, it combines some aspects of the metrics collection tools with an integrated storage and visualisation tool similar to Graphite.</p>

<p>Monitoring checks is a bit more painful. I’ve been experimenting with <a href="http://sensuapp.org/">Sensu</a> in hope of not installing Nagios. Nagios works but it’s just a bit ungainly. But you do need somewhere to write checks against metrics or other aspects of your system and to issue alerts.</p>

<p>At this point everyone loves dashboards, and <a href="http://shopify.github.io/dashing/">Dashing</a> is particularly lovely. <a href="https://github.com/paperlesspost/graphiti">Graphiti</a> and <a href="https://github.com/obfuscurity/tasseo">Tasseo</a> for Graphite are useful too.</p>

<p>For bonus points things like <a href="http://flapjack.io/">Flapjack</a> and <a href="http://riemann.io/">Reimann</a> provide some interesting extra capabilities around alert control or real time monitoring respectively.</p>

<p>And for that elusive top of the class grade take a look at <a href="http://codeascraft.com/2013/06/11/introducing-kale/">Kale</a>, which provides anomaly detection on top of Graphite and Elasticsearch .</p>

<p>You might be thinking that’s a lot of moving parts and you’d be right. If you’re a small project running all of that is too much overhead, turning to something like Zabbix might be more sensible.</p>

<p>Depending on money/sensitivity/control issues lots of nice and not so
nice commercial products exist. <a href="http://www.circonus.com/">Circonus</a>, <a href="http://www.splunk.com/">Splunk</a>, <a href="http://newrelic.com/">New Relic</a>, <a href="http://boundary.com/">Boundary</a> and <a href="https://metrics.librato.com/">Librato Metrics</a> are all lovely in different ways and provide part of the puzzle.</p>

<p>And that’s just the boring matter of tools. Now you get into alert design and other gnarly people stuff.</p>

<p>If you got this far you should watch all the <a href="http://vimeo.com/monitorama">Monitorama videos</a> too.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Platform as a Service and the network gap]]></title>
    <link href="http://www.morethanseven.net/2013/08/11/platform-as-a-service-and-the-network-gap/"/>
    <updated>2013-08-11T14:00:00+01:00</updated>
    <id>http://www.morethanseven.net/2013/08/11/platform-as-a-service-and-the-network-gap</id>
    <content type="html"><![CDATA[<p><em>Originally published on <a href="https://medium.com/p/817849715f0a">Medium</a>.</em></p>

<p>I&#8217;m a big fan of the Platform as a Service (PaaS) model of operating web
application infrastructure. But I&#8217;m a much bigger user and exponent of
Infrastructure as a Service (IaaS) products within my current role
working for the UK Government. This post describes why that is, and
hopefully helps anyone else inside other large enterprise organisations
reason about the advantages and disadvantages, and helps PaaS vendors
and developers understand what I personally thing is a barrier to
adoption in that type of organisation.</p>

<p>A quick word of caution, I don’t know every product inside out. It’s
very possible a PaaS product exists that deals with the problems I will
describe. If you know of such a product do let me know.</p>

<h2>A simple use case</h2>

<p>PaaS products make for the very best demos. Have a working application?
Deployment is probably as simple as:</p>

<pre><code>git push azure master 
</code></pre>

<p>Your app has started to run slowly because visitors are flooding in?
Just scale out with something like:</p>

<pre><code>heroku ps:scale web+2
</code></pre>

<p>The amount of complexity being hidden is astounding and the ability to
move incredibly quickly is obvious for anyone with experience of doing
this in a more traditional organisation.</p>

<h2>A not so simple use case</h2>

<p>Even small systems are often being built out of many small services
these days. Many large organisations have been up to this for a while
under the banner of Service Orientated Architecture. I&#8217;m a big fan of
this approach, in my view it moves operational and organisational
complexity back into the development team where its impact can often be
minimised by automation. But that’s a topic for another post.</p>

<p>In a PaaS world having many services is fine. We just have more
applications running on the Platform which can be independently scaled
out to meet our needs. But services need to communicate with each other
somehow, and this is where our problems start. We’ll keep things simple
here by assuming communication is over HTTPS (which should be pretty
typical) but I don’t think other protocols make the problem I have go
away. The same problem applies if you’re using a SaaS database for
example.</p>

<h2>It’s the network, stupid</h2>

<p>Over what network does my HTTPS internal service call travel? The
internet? The internal PaaS vendor’s network? If the latter, is my
traffic travelling over the same network as other clients on the
platform? Maybe I&#8217;m running my own PaaS in-house. But do I trust
everyone else in my very large organisation and want my traffic on the
same network as other things I don’t even know about? Even if it’s just
me do I want internal service traffic mixing with requests coming from
the internet? And are all my services created equally with regards what
they can and cannot access?</p>

<p>Throw in questions like: is the PaaS supplier running on infrastructure
provided by a public IaaS suppliers who you don’t have a relationship
with and you start to question the suitability of the current public
PaaS products for building secure service based systems.</p>

<h2>A journey into Enterprise Architectures</h2>

<p>You might be thinking, pah, what’s the worst that can happen? If you
work for a small company or a shiny startup that might be completely
valid. If on the other hand you’re working in a regulated environment
(say PCI) or dealing with large volumes of highly sensitive information
you’re very likely to have to build systems that provide layers of
trust, and to be doing inspection, filtering and integrity checking as
requests flow between those layers.</p>

<p>Imagine that I have a service dealing with some sensitive data. If I
control the infrastructure (virtualised or not, IaaS provided or not)
I’ll make sure that service endpoint isn’t available to anything that
doesn’t need access to it via my network configuration. If I’m being
more thorough I’ll filter traffic through some sort of proxy that does
checking of the content; It should be JSON (or XML), it should meet this
schema, It shouldn’t exceed this rate, it shouldn’t exceed this payload
size or response size, etc. That is before anything even reaches the
services application. And that’s on top of SSL and maybe client
certificates.</p>

<p>If I don’t control the infrastructure, for example when running on a
PaaS, I lose some of the ability to have the network protect me. I can
probably get some of this back by running my own PaaS on my own
infrastructure, but without awareness and a nice interface to that
functionality at the PaaS layer I’m going to lose lots of the benefits
of running the PaaS in the first place. It’s nice that I can scale my
application out, but if new instances can’t connect to the required
backend services without some additional network configuration that’s
invisible to the PaaS what use is that?</p>

<p>The question becomes; how to implement security layers within existing
PaaS products (without changing them). And my answer is “I don’t know”.
Yet.</p>

<h2>Why isn’t SSL enough?</h2>

<p>SSL doesn’t help as much as you’d like to think here because if I’m an
attacker what I’m probably going to attack is your buggy code rather
than the transport mechanism. SSL doesn’t protect you from SQL injection
or unpatched software or zero-day exploits. If the only thing that my
backend service will talk to is my frontend application, an attacker has
to compromise two things rather than just ignore the frontend and go
after the data. Throw in a filter as described above and it’s really
three things that need to be overcome.</p>

<h2>The PaaS/IaaS interface</h2>

<p>I think part of the solution lies in exposing some of the underlying
infrastructure via the PaaS interface. IaaS is often characterised as
compute, storage and network. In my experience everyone forgets the
network part. In a PaaS world I don’t want to be exposed to storage
details (I just want it to appear infinite and pay for what I use) or
virtual machines (I just care about computing power, say RAM, not the
number of machines I’m running on) but I think I do, sometimes, want to
be exposed to the (virtual) network configuration.</p>

<p>Hopefully someone working on OpenShift or CloudFoundry or Azure or
Heroku or DotCloud or insert PaaS here is already working on this. If
not maybe this post will prompt someone to do so.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Web application security tools]]></title>
    <link href="http://www.morethanseven.net/2013/04/23/web-application-security-tools/"/>
    <updated>2013-04-23T07:57:00+01:00</updated>
    <id>http://www.morethanseven.net/2013/04/23/web-application-security-tools</id>
    <content type="html"><![CDATA[<p>I&#8217;ve become increasingly interested in web application security issues over the last year or so. Working in Government will do that to you. And I&#8217;ve come to the conclusion that a) there are lots of good open source security tools, b) many of them are terribly packaged and c) most developers don&#8217;t use any of them.</p>
<p>I&#8217;ve been having related conversations at recent events I&#8217;ve made it along to, including Devopsdays London which featured some good open spaces discussions on the subject. Security is one of those areas that, for many organisations, is basically outsourced to third party penetration testing firms or consultants. Specialists definitely have a role to play, but with a move towards increasingly rapid releases I think in-house security testing and monitoring is going to get more and more important.</p>
<h2>A collection of security tools</h2>
<p>I&#8217;ve started to build a <a href="https://github.com/garethr/pentesting-playground">collection of tools on GitHub</a>, along with a vagrant setup to test them out. Full instructions are available on that repository but the short version is you can run one command and have one virtual machine filled with security testing tools and, if useful, another machine running a vulnerable web application with which to test. The current list of tools runs to:</p>
<ul>
	<li><a href="http://code.google.com/p/skipfish/">skipfish</a></li>
	<li><a href="http://nmap.org/">nmap</a></li>
	<li><a href="http://www.cirt.net/nikto2">nikto</a></li>
	<li><a href="http://w3af.org/">w3af</a></li>
	<li><a href="https://github.com/mozilla/Garmr">garmr</a></li>
	<li><a href="https://github.com/iSECPartners/sslyze">sslyze</a></li>
	<li><a href="https://github.com/metachris/wpscanner">wpscanner</a></li>
	<li><a href="https://www.owasp.org/index.php/OWASP_Zed_Attack_Proxy_Project">owasp zap</a></li>
	<li><a href="http://arachni-scanner.com/">arachni</a></li>
	<li><a href="https://github.com/gauntlt/gauntlt">gauntlt</a></li>
	<li><a href="http://sqlmap.org/">sqlmap</a></li>
	<li><a href="http://wpscan.org/">wpscan</a></li>
	<li><a href="http://sourceforge.net/projects/sslscan/">sslscan</a></li>
	<li><a href="http://blog.taddong.com/2013/02/tlssled-v13.html">TLSSLed</a></li>
</ul>
<p>But I&#8217;ll add more tools as I discover them or as people file issues or pull requests.</p>
<h2>What about Backtrack?</h2>
<p>When I started investigating tools for security and penetration testing most roads led to <a href="http://www.backtrack-linux.org/">Backtrack</a>. This is a complete Linux distribution packed with a huge number of security tools, including many if not all of the above. Why then did I write puppet code rather than create a Vagrant box from Backtrack? Firstly, Backtrack is probably great if you&#8217;re a professional penetration tester, but the barrier to entry to installing a new distibution for most developers is too high in my view. And with a view to using some of these tools as part of monitoring systems I don&#8217;t always want a separate virtual machine. I want to be able to install the tools wherever I want. A good configuration management tool gives you that portability, and Vagrant gives you all the benefits of a local virtual machine.</p>
<h2>Future plans</h2>
<p>As mentioned I&#8217;d like to expand how some of these tools are used to include automated monitoring of applications, maybe look at ways of extracting data for metrics or possibily writing a Sensu plugin or two. The first step to that is probably breaking down the monolithic puppet manifest into separate modules for each tool. Along the way I can add support for more operating systems as required. I&#8217;ve already done that for the <a href="http://forge.puppetlabs.com/garethr/wackopicko">wackopicko module which is up on the Forge</a>.</p>
<p>I&#8217;m also soliciting any and all feedback, especially from developers who don&#8217;t do any security related testing but feel like they should.</p>]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Government Service Design Manual]]></title>
    <link href="http://www.morethanseven.net/2013/03/23/government-service-design-manual/"/>
    <updated>2013-03-23T17:04:00+00:00</updated>
    <id>http://www.morethanseven.net/2013/03/23/government-service-design-manual</id>
    <content type="html"><![CDATA[<p>I&#8217;ve not been writing many blog posts lately, but I have been doing quite a bit of writing elsewhere. One of the things I&#8217;ve had a hand in at work is the new <a href="https://www.gov.uk/service-manual">Government Service Design Manual</a>. This is the work of many people I work with as well as further afield. It&#8217;s intended to be a good starting place to find information about building high quality digital services.</p>
<p>The manual is in beta and we&#8217;re looking for as much feedback as possible on the whole thing. It&#8217;s already proving useful and a good way of framing the scope of discussions, but it has lots of room for improvement.</p>
<p>If you&#8217;re reading this post I&#8217;m going to wager you&#8217;re interest lies in or around devops flavoured content. The following are guides I&#8217;ve written in this area that I&#8217;d love any and all feedback on.</p>
<ul>
	<li><a href="https://www.gov.uk/service-manual/the-team/web-operations.html">Web Operations</a></li>
	<li><a href="https://www.gov.uk/service-manual/making-software/configuration-management.html">Configuration Management</a></li>
	<li><a href="https://www.gov.uk/service-manual/operations/hosting.html">Hosting</a></li>
	<li><a href="https://www.gov.uk/service-manual/making-software/information-security.html">Information Security</a></li>
	<li><a href="https://www.gov.uk/service-manual/operations/monitoring.html">Monitoring</a></li>
	<li><a href="https://www.gov.uk/service-manual/operations/load-and-performance-testing.html">Load and Performance Testing</a></li>
	<li><a href="https://www.gov.uk/service-manual/making-software/release-strategies.html">Releasing Software</a></li>
	<li><a href="https://www.gov.uk/service-manual/operations/penetration-testing.html">Vulnerability and Penetration Testing</a></li>
	<li><a href="https://www.gov.uk/service-manual/making-software/choosing-technology.html">Choosing Technology</a></li>
</ul>
<p>If you&#8217;re interested in the background to this endeavour then a couple of blog posts from some of my colleagues might be of interest too. First Richard Pope talks about <a href="http://digital.cabinetoffice.gov.uk/2013/03/21/building-the-standard/">how the manual came about</a> and here&#8217;s a post from Andrew Greenway about this <a href="http://digital.cabinetoffice.gov.uk/2013/03/21/building-the-standard/">beta testing of the service standard</a>.</p>
<p>The source for all this is on <a href="https://github.com/alphagov/government-service-design-manual">GitHub</a> so if you prefer you can just sent a pull request. Or I&#8217;m happy to get emails or comments on this post. In particular if people have good references or next steps for these guides then let me know as several of them in particular are lacking in that area.</p>]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Perils of portability]]></title>
    <link href="http://www.morethanseven.net/2013/03/23/perils-of-portability/"/>
    <updated>2013-03-23T16:36:00+00:00</updated>
    <id>http://www.morethanseven.net/2013/03/23/perils-of-portability</id>
    <content type="html"><![CDATA[<p>I had fun speaking at <a href="http://qconlondon.com/">QCon</a> in London earlier this month with a talk on the Cloud track entitled the Perils of Portability.</p>
<p>This had some Governmenty stuff in but was mainly part rant, part hope for the future of cloud infrastructure. I had some great conversations with people afterwards who felt some of the similar pain which was nice to know. I also somehow managed to get 120 slides into a 40 minute presentation which I think is a personal records.</p>
<script async class="speakerdeck-embed" data-id="52f90c206ae90130747512313d140c86" data-ratio="1.33333333333333" src="http://www.morethanseven.net//speakerdeck.com/assets/embed.js"></script><p>The videos will be available at some point in the not too distant future too.</p>]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[March madness]]></title>
    <link href="http://www.morethanseven.net/2013/02/17/march-madness/"/>
    <updated>2013-02-17T17:17:00+00:00</updated>
    <id>http://www.morethanseven.net/2013/02/17/march-madness</id>
    <content type="html"><![CDATA[<p>With only a week or so to go before the end of February, it&#8217;s looking like March might be a little busy.</p>
<ul>
	<li>I&#8217;m speaking at QCon, in London on Wednesday 6th on <a href="http://qconlondon.com/london-2013/presentation/Clouds%20in%20Government%20-%20Perils%20of%20Portability">Clouds in Government &#8211; Perils of Portability</a> (which in hindsight is probably the silliest title for a talk I&#8217;ve ever used)</li>
	<li>On the 15th and 16th of March I&#8217;ll be at <a href="http://devopsdays.org/events/2013-london/">Devopsdays</a>, again in London. I&#8217;ve been helping out with organising the event and I&#8217;m very much looking forward to going along after seeing all the work being put in.</li>
	<li>And last but not least I&#8217;m heading to Boston for the rather exciting <a href="http://monitorama.com/">Monitorama</a> from the 26th until the 30th. Looking forward to meeting up in person with quite a few folks I&#8217;ve spoken to over the last year or two.</li>
</ul>
<p>If you&#8217;re going to be at any of these events (QCon and Devopsdays still have tickets available I think) then let me know.</p>]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Going fast in government]]></title>
    <link href="http://www.morethanseven.net/2013/02/17/going-fast-in-government/"/>
    <updated>2013-02-17T17:08:00+00:00</updated>
    <id>http://www.morethanseven.net/2013/02/17/going-fast-in-government</id>
    <content type="html"><![CDATA[<p>About a month ago I had the good fortune of speaking at the <a href="http://www.meetup.com/London-Web-Performance-Group/">London Web Performance</a> meetup. This was one of the first talks I&#8217;ve done about our work at The Government Digital Service since the luanch of <span class="caps">GOV</span>.UK back in October. The topic was all about moving quickly in a large organisation (The UK Civil Service is about 450,000 people so I think it counts) and featured just a hand full of technical and organisational tricks we used.</p>
<script async class="speakerdeck-embed" data-id="bc48ed2042c20130b322123138156909" data-ratio="1.33333333333333" src="http://www.morethanseven.net//speakerdeck.com/assets/embed.js"></script>]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Django and Rails presentation from QCon]]></title>
    <link href="http://www.morethanseven.net/2013/01/13/django-and-rails-presentation-from-qcon/"/>
    <updated>2013-01-13T16:31:00+00:00</updated>
    <id>http://www.morethanseven.net/2013/01/13/django-and-rails-presentation-from-qcon</id>
    <content type="html"><![CDATA[<p>I had great fun back in November at the <a href="http://qconsf.com/">QCon</a> conference in San Francisco. As well as currating one of the tracks and catching up with people in the area I managed to give the following talk.</p>
<script async class="speakerdeck-embed" data-id="7e1dd5a03efc0130083b123139173def" data-ratio="1.33333333333333" src="http://www.morethanseven.net//speakerdeck.com/assets/embed.js"></script><p>In hindsight it might have been a bit odd to try and cover both Rails and Django examples in the one presentation but it was quite good fun putting together code examples using both of them at the same time. As well as a large set of tips, tricks and tools I settled on a few things that I think any web (or other) framework should support out of the box.</p>
<ul>
	<li>A debug toolbar</li>
	<li>Transparent caching support</li>
	<li>Hooks for instrumentation</li>
	<li>Configurable logging</li>
</ul>]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[my personal package repository]]></title>
    <link href="http://www.morethanseven.net/2012/12/30/my-personal-package-repository/"/>
    <updated>2012-12-30T16:52:00+00:00</updated>
    <id>http://www.morethanseven.net/2012/12/30/my-personal-package-repository</id>
    <content type="html"><![CDATA[<p>I&#8217;m a <a href="http://www.morethanseven.net/2011/01/16/Why-developers-should-care-about-system-packages/">big fan of system packages for lots of reasons</a> and have often ended up rolling my own debian package repository at work, or working with others that have done so. Recently I finally got round to setting up a personal package repo, at <a href="http://packages.garethrushgrove.com">packages.garethrushgrove.com</a>. More interesting than the repo is probably the tool chain I used, oh and the rather nice bootstrap based styling.</p>
<p><img src="http://image-host.appspot.com/i/img?id=agppbWFnZS1ob3N0cg0LEgVJbWFnZRjh1wIM" alt="nice looking package repository"/></p>
<p>The source code for everything is <a href="https://github.com/garethr/packages">on GitHub</a> although not much documentation exists yet. In the middle are a few shell scripts that generate the repo. Around them is a Vagrant box (which makes it easier to build packages for different achitectures or distros) and some Rake commands</p>
<pre><code>bundle exec rake -T
rake recipes:build[recipe]  # Build a package from one of the available recipes
rake recipes:list           # List available recipes
rake repo:build             # Build the repository</code></pre>
<p>The recipes commands allow for building new packages based on scripts. A few examples are included which use fpm, but you could use anything. The repo:build command triggers the debian repository to be rebuilt.</p>
<p>The vagrant configuration shares various folders between and guest and host which also opens up a few useful features. One is I can just drop any old debian package into the debs folder and run the repo:build command and it will be in my repository. The other useful capability is that the resulting repo is shared back to the host, which means I can then check it into Git and in my case push it up to Heroku.</p>]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[On the forge]]></title>
    <link href="http://www.morethanseven.net/2012/12/03/on-the-forge/"/>
    <updated>2012-12-03T08:18:00+00:00</updated>
    <id>http://www.morethanseven.net/2012/12/03/on-the-forge</id>
    <content type="html"><![CDATA[<p>I&#8217;ve been spending a bit of time recently pushing a few Puppet modules to the <a href="http://forge.puppetlabs.com">Forge</a>. This is Puppetlabs attempt to make a central repository of reusable puppet modules. I started doing it as a bit of an experiment, to find out what I liked and what worked and I decided to writeup a few opinions.</p>
<p>So far I&#8217;ve shipped the following modules:</p>
<ul>
	<li><a href="http://forge.puppetlabs.com/garethr/riemann">Riemann</a></li>
	<li><a href="http://forge.puppetlabs.com/garethr/graphite">Graphite</a></li>
	<li><a href="http://forge.puppetlabs.com/garethr/logstash">Logstash</a></li>
	<li><a href="http://forge.puppetlabs.com/garethr/freight">Freight</a></li>
</ul>
<p>Quite a few of these started as forks of other modules but have evolved quite a bit towards being more reusable.</p>
<p>I&#8217;ve also started sending pull requests for modules that basically do what I want but don&#8217;t always play well with others.</p>
<ul>
	<li><a href="https://github.com/thomasvandoren/puppet-redis/pull/10">Redis</a></li>
</ul>
<h2>Improved tools</h2>
<p>It turns out the experience is mainly a pleasurable one, partly down to the much improved tooling around Puppet. Specifically I&#8217;m making extensive use of:</p>
<ul>
	<li><a href="http://rspec-puppet.com/">Rspec Puppet</a> &#8211; for writing tests for module behavious</li>
	<li><a href="https://github.com/rodjek/librarian-puppet">Librarian Puppet</a> &#8211; dependency management for modules</li>
	<li><a href="https://github.com/puppetlabs/puppetlabs_spec_helper">Puppet spec helper</a> &#8211; conventions and helpers for testing modules</li>
	<li><a href="https://travis-ci.org/">Travis CI</a> &#8211; easy continuous integration for module code</li>
	<li><a href="http://vagrantup.com/">Vagrant</a> &#8211; manage virtual machines, useful for smoke testing on different distributions</li>
</ul>
<p>Lots of those tools make testing Puppet modules both easier and useful. Here&#8217;s an example of one of the above modules being tested. Note that it&#8217;s run across Ruby 1.8.7, 1.9.2 and 1.9.3 and Puppet versions 2.7.17, 2.7.18 and 3.0.1 for a total of 9 builds. Handily the Redis module mentioned also had a test suite. The pull request includes changes to that, and Travis <a href="https://travis-ci.org/thomasvandoren/puppet-redis/builds/3462513">automatically tested the pull request</a> for the modules author.</p>
<h2>Antipatterns</h2>
<p>Using modules from the Forge really forces you to think about reusability. The pull request mentioned above for the Redis module for instance replaced an explicit mention of the build-essential package with the &#8220;puppetlabs/gcc&#8221;: class from the Forge. This makes the module less self contained, but without that change the module is incompatible with any other module that also uses that common package. I also went back and replaced explicit references to wget and build-essential in my Riemann module.</p>
<p>As a rule of thumb. For a specific module only include resources that are unique to the software the module manages. Anything else should be in another module with a dependency in the Modulefile.</p>
<p>This can feel a little much when you&#8217;re replacing a simple Package resource with a whole new module but it has two advantages I care about. As well as the ability to use the module with other third party modules more easily it also makes it more likely that the module will work cross platform.</p>
<h2>What&#8217;s missing?</h2>
<p>I&#8217;d like to see a few things improved when it comes to the Forge.</p>
<ul>
	<li>I&#8217;d like to be able to publish a new version of a module without having to use the web interface. The current workflow involves running a build command, then uploading the generated artifact via a web form after logging in.</li>
	<li>I&#8217;d like to see best practice module development guides front and centre on the Forge. Lots of modules won&#8217;t work with other modules and I think that&#8217;s fixable.</li>
	<li>Integration with puppet-lint would be nice, giving some indication of whether the authors care about the Puppet styleguide.</li>
	<li><del>A command line search interface would be useful</del>. And <a href="http://docs.puppetlabs.com/man/module.html">turns out to exist</a>. Thanks <a href="http://twitter.com/a1cy">@a1cy</a> for the heads up.</li>
	<li>The Forge tracks number of downloads, but as a publisher I don&#8217;t know how often my modules have been downloaded.</li>
	<li>And finally I&#8217;d like to see more people using it.</li>
</ul>]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Shipping]]></title>
    <link href="http://www.morethanseven.net/2012/10/21/shipping/"/>
    <updated>2012-10-21T21:50:00+01:00</updated>
    <id>http://www.morethanseven.net/2012/10/21/shipping</id>
    <content type="html"><![CDATA[<p>Last week we shipped <a href="https://www.gov.uk"><span class="caps">GOV</span>.UK</a>. Over the last year we&#8217;ve built a team to build a website. Now we&#8217;re busy building a culture too. I&#8217;ve got so much that needs writing up about everything we&#8217;ve been up to. Hopefully I&#8217;ll make a start in the next week or so.</p>]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Tale Of A Grok Pattern]]></title>
    <link href="http://www.morethanseven.net/2012/08/19/Tale-of-a-grok-pattern/"/>
    <updated>2012-08-19T00:00:00+01:00</updated>
    <id>http://www.morethanseven.net/2012/08/19/Tale-of-a-grok-pattern</id>
    <content type="html"><![CDATA[<p>I&#8217;m all of a sudden adding lots more code to GitHub. Here&#8217;s the latest project, <a href="https://github.com/garethr/logstash-patterns">grok patterns for logstash</a>. At the moment this repo only contains one new pattern but I&#8217;m hoping to add more, and maybe even for others to add more too.</p>
<p>First, a bit of background. <a href="http://logstash.net/">Logstash</a> is the excellent, open source, log agregation and processing framework. It takes inputs from various configurable places, processes them with filters and then outputs the results. So maybe you&#8217;ll take inputs from various application log files and output then into an elastic search index for easy searching, or output the same inputs to graphite and statsd to get graphs of rates. One of the host powerful filters in logstash is the <a href="http://logstash.net/docs/1.0.17/filters/grok">grok filter</a>. It takes a grok pattern and parses out information contained in the text into fields that can be more easily used by outputs. This post serves hopefully as both an explanation of why and an example of how you might do that.</p>
<h2>The problem</h2>
<p>Rails logs are horrible, that is until you install the excellent <a href="https://github.com/roidrage/lograge">lograge</a> output formatter. That gives you lines like:</p>
<pre>GET /jobs/833552.json format=json action=jobs#show status=200 duration=58.33 view=40.43 db=15.26</pre>
<p>This contains loads of useful information that&#8217;s easily parsable by a developer. We have the <span class="caps">HTTP</span> status code, the rails controller and information about response time too. A grok filter lets us teach logstash about that information too. The working grok filter for filtering this line looks like this:</p>
<h2>The solution</h2>
<pre>LOGRAGE %{WORD:method}%{SPACE}%{DATA}%{SPACE}action=%{WORD:controller}#%{WORD:action}%{SPACE}status=%{INT:status}%{SPACE}duration=%{NUMBER:duration}%{SPACE}view=%{NUMBER:view}(%{SPACE}db=%{NUMBER:db})?%{GREEDYDATA}</pre>
<p>That was worked out pretty much with a bit of trial and error and use of the logstash java binary, using stdin and stdout inputs and outputs. It works but getting their wasn&#8217;t that much funand proving it works outside a running logstash setup was tricky. Enter rspec and the grok implementation in pure Ruby. The project above contains an Rspec matcher for use when testing grok filters for logstash. I&#8217;ll probably extract that into a gem at some point but you&#8217;ll get the idea. Now we can write tests like these:</p>
<pre>the lograge grok pattern
  with a standard lograge log line
    should have the correct http method value
    should have the correct value for the request duration
    should have the correct value for the request view time
    should have the correct controller and action
    should have the correct value for db time
  without the db time
    should have the correct value for the request view time
  with a post request
    should have the correct http method value

Finished in 0.01472 seconds
7 examples, 0 failures
</pre>
<p>The <a href="https://github.com/garethr/logstash-patterns/blob/master/spec/lograge_spec.rb">tests themselves</a> are just basic Rspec with most of the work done in the <a href="https://github.com/garethr/logstash-patterns/blob/master/spec/spec_helper.rb">custom matcher</a>. This not only means I can be a bit more confident that my grok pattern works, it also provides a much nicer framework for writing more patterns for other log formats. Parsing rules like this are one area where test driven development is a huge boon in my experience. And with tests comes continuous integration, in this case via <a href="http://travis-ci.org/#!/garethr/logstash-patterns">Travis</a>.</p>
<p>I&#8217;ll hopefully find myself writing more patterns and tests for them, and if anyone wants to send pull requests and to start collecting working grok patterns together so much the better.</p>]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Riemann Puppet Module]]></title>
    <link href="http://www.morethanseven.net/2012/08/11/Riemann-puppet-module/"/>
    <updated>2012-08-11T00:00:00+01:00</updated>
    <id>http://www.morethanseven.net/2012/08/11/Riemann-puppet-module</id>
    <content type="html"><![CDATA[<p>Thanks to an <a href="https://twitter.com/bitprophet/status/233626675307479040">errant tweet</a> I started playing with <a href="http://aphyr.github.com/riemann/">Riemann</a> again. It ticks lots of boxes for me, from the clojure to configuration as code and the overloadable dashboard application. What started as using Puppet and Vagrant to investigate Riemann turned into a full blown tool and module writing exercise, resulting in two related projects on GitHub.</p>
<ul>
	<li><a href="https://github.com/garethr/garethr-riemann/">garethr-riemann</a> is a Puppet module for installing and configuring Riemann. It allows for easily specifying your own server configuration and dashboard views.</li>
	<li><a href="https://github.com/garethr/riemann-vagrant">riemann-vagrant</a> is a Vagrantfile and other code which uses above puppet module to setup a local testing environment.</li>
</ul>
<p>I like this combination, a separate Puppet module along with a vagrant powered test bed. I&#8217;ve written a reasonable rspec based test suite to check the module but it&#8217;s always easier to be able to run <em>vagrant provision</em> as well to check everything is working. This also turned out to be the perfect opportunity to use <a href="https://github.com/rodjek/librarian-puppet">Librarian-Puppet</a> to manage the dependencies and eventually to ship the module to the <a href="https://forge.puppetlabs.com/garethr/riemann">Puppet Forge</a>.</p>]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[The Vagrantbox.es Story]]></title>
    <link href="http://www.morethanseven.net/2012/07/01/The-vagrantbox.es-story/"/>
    <updated>2012-07-01T00:00:00+01:00</updated>
    <id>http://www.morethanseven.net/2012/07/01/The-vagrantbox.es-story</id>
    <content type="html"><![CDATA[<p>A few weeks ago now <a href="http://www.vagrantbox.es/">Vagrantbox.es</a> (a website I maintain for third party hosted <a href="http://vagrantup.com/">Vagrant</a> base boxes) dissapeared from the internet for a few days. This was completely my fault, the (lovely) hosting people <a href="https://www.ep.io/">ep.io</a> had unfortunately closed down the service they had in beta and I&#8217;d been so busy that I hadn&#8217;t had chance to move it elsewhere.</p>
<p>The original version of the site (I had the code and good backups of the data) was a pretty simple Django application, but I&#8217;d used it to experiment (read over-engineer) with various bits of tech including Varnish, Solr, some <span class="caps">ORM</span> caching and lots more. This had been great, but it made it less portable. I had everything described in Puppet, but with virtually no spare time I decided to go a different route.</p>
<p>I threw a flat version of the site up on <a href="https://github.com/garethr/vagrantboxes-heroku">GitHub</a>, served it using Nginx on <a href="http://www.heroku.com/">Heroku</a> and added a quick <em>Fork me on GitHub</em> badge to the top. Suggest a box moved from being a web form to a pull request. It&#8217;s fair to say I did this pretty quickly and made a good few typos on the way. But within a couple of weeks I&#8217;ve had 8 pull requests either fixing my bugs, removing dead boxes and adding new ones.</p>
<p>What I&#8217;m going to take from this is, if you&#8217;re building a community project that&#8217;s aimed at developers, then throw the content on GitHub. In my case I have the entire site on there too but I think that&#8217;s secondary. Pull requests are much better than any content management system or workflow you&#8217;re likely to build, and even more importantly the time to implement something drops hugely.</p>
<p>With all the spare time I don&#8217;t have I&#8217;ll be thinking about a content management model using GitHub for content, pull requests for workflow and post commit hooks for loading that content into a site or service somewhere.</p>]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Static Sites With Nginx On Heroku]]></title>
    <link href="http://www.morethanseven.net/2012/06/05/Static-sites-with-nginx-on-heroku/"/>
    <updated>2012-06-05T00:00:00+01:00</updated>
    <id>http://www.morethanseven.net/2012/06/05/Static-sites-with-nginx-on-heroku</id>
    <content type="html"><![CDATA[<p>I have a few static sites on Heroku but in one case in particular I already had quite an involved nginx configuration &#8211; mainly 410s for some previous content and a series of redirects from older versions of the site. The common way of having static sites on Heroku appears to be to use a simple Rack middleware, but that would have meant reimplementing lots of boring redirect logic.</p>
<p>Heroku <a href="https://devcenter.heroku.com/articles/buildpacks">buildpacks</a> are great. The newer cedar stack is no longer tied to a particular language or framework, instead all of the discovery and knowledge about particular software is put into a buildpack. As well as the Heroku provided list it&#8217;s possible to write you&#8217;re own. Or in this case use one someone has <a href="https://github.com/essh/heroku-buildpack-nginx">created earlier</a>.</p>
<p>I&#8217;ve just moved <a href="http://www.vagrantbox.es/">Vagrantbox.es</a> over to Heroku due to the closure of a previous service. In doing that, instead of the simple database backed app, I&#8217;ve simply thrown all the content onto <a href="https://github.com/garethr/vagrantboxes-heroku">GitHub</a>. This means anyone can fork the content and send pull requests. Hopefully this should mean I pay a bit more attention to suggestions and new boxes.</p>
<p>The repository is a nice simple example of using the mentioned Heroku Nginx buildpack too. You just run the following command to create a new Heroku application.</p>
<pre>heroku create --stack cedar --buildpack http://github.com/essh/heroku-buildpack-nginx.git</pre>
<p>And then in typical Heroku fashion use a git remote to deploy changes and updates. The repository is split into a <em>www</em> folder with the site content and a <em>conf</em> folder with the nginx configuration. The only clever parts involve the use of an <span class="caps">ERB</span> template for the nginx configuration file so we can pickup the correct port. We also use 1 worker process and don&#8217;t automatically daemonize the process &#8211; Heroku deals with this itself.</p>]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Self Contained Jruby Web Applications]]></title>
    <link href="http://www.morethanseven.net/2012/04/06/Self-contained-jruby-web-applications/"/>
    <updated>2012-04-06T00:00:00+01:00</updated>
    <id>http://www.morethanseven.net/2012/04/06/Self-contained-jruby-web-applications</id>
    <content type="html"><![CDATA[<p>Several things seemed to come together at once to make me want to hack on this particular project. In no particular order:</p>
<p>The <a href="http://www.thoughtworks.com/articles/technology-radar-march-2012">Thoughtworks Technology Radar</a> said the following:</p>
<blockquote>
<p>Embedding a servlet container, such as Jetty, inside a Java application has many advantages over running the application inside a container. Testing is relatively painless because of the simple startup, and the development environment is closer to production. Nasty surprises like mismatched versions of libraries or drivers are eliminated by not sharing across multiple applications. While you will have to manage and monitor multiple Java Virtual Machines in production using this model, we feel the advantages offered by the simplicity and isolation are significant.</p>
</blockquote>
<p>I&#8217;ve been getting more interested in JRuby anyway, partly because we&#8217;re finding ourselves using both Ruby and Scala at work, and maintaining a single target platform makes sense to me. Throw in the potential for interop between those languages and it&#8217;s certainly worth investigating.</p>
<p><a href="http://www.playframework.org/">Play 2.0</a> shipped and currently only provides the ability to create a self contained executable with bundled web server. Creating <span class="caps">WAR</span> files for more traditional application servers is on the roadmap but interestingly wasn&#8217;t deemed essential for the big 2.0 release. I had a nice chat with <a href="https://twitter.com/minglis">Martyn Inglis</a> at work about some of the nice side effects of this setup.</p>
<p>And throw in every time I have to configure straight Ruby applications for production environments I get cross. I know where all the bits and pieces are buried and can do it well, but with so many moving parts it&#8217;s absolutely no fun whatsoever.</p>
<p>Warbler, the JRuby tool for creating <span class="caps">WAR</span> files from Ruby source, has just added the ability to <a href="https://github.com/jruby/warbler/commit/0558a285eb59a0801cf7c0f274777b06b63883b3">embed Jetty to the master branch</a>.</p>
<p>I decided to take all of this for a quick spin, and the <a href="https://github.com/garethr/jruby-embedded-jetty">resulting code is up on GitHub</a>.</p>
<p>This is the simplest Rack application possible, it just prints <em>Hello Jetty</em>. And the <span class="caps">README</span> covers how to install and run it so I won&#8217;t duplcate that information here.</p>
<p>But I will print some nearly meaningless and unscientific benchmarks because, hey, who doesn&#8217;t like those?</p>
<pre>⚡ ab -c 50 -n 5000 http://localhost:8090/

Server Software:        Jetty(8.y.z-SNAPSHOT)
Server Hostname:        localhost
Server Port:            8090

Document Path:          /
Document Length:        16 bytes

Concurrency Level:      50
Time taken for tests:   1.827 seconds
Complete requests:      5000
Failed requests:        0
Write errors:           0
Total transferred:      555999 bytes
HTML transferred:       80144 bytes
Requests per second:    2736.47 [#/sec] (mean)
Time per request:       18.272 [ms] (mean)
Time per request:       0.365 [ms] (mean, across all concurrent requests)
Transfer rate:          297.16 [Kbytes/sec] received

Connection Times (ms)
              min  mean[+/-sd] median   max
Connect:        0    2   2.2      1      18
Processing:     1   16   7.7     15      61
Waiting:        0   14   7.2     13      57
Total:          2   18   7.5     17      61

Percentage of the requests served within a certain time (ms)
  50%     17
  66%     19
  75%     21
  80%     22
  90%     27
  95%     30
  98%     42
  99%     52
 100%     61 (longest request)
</pre>
<p>Running the same test on the same machine but using Ruby 1.9.2-p290 and Thin gives.</p>
<pre>Server Software:        thin
Server Hostname:        localhost
Server Port:            9292

Document Path:          /
Document Length:        16 bytes

Concurrency Level:      50
Time taken for tests:   3.125 seconds
Complete requests:      5000
Failed requests:        0
Write errors:           0
Total transferred:      620620 bytes
HTML transferred:       80080 bytes
Requests per second:    1600.16 [#/sec] (mean)
Time per request:       31.247 [ms] (mean)
Time per request:       0.625 [ms] (mean, across all concurrent requests)
Transfer rate:          193.96 [Kbytes/sec] received

Connection Times (ms)
              min  mean[+/-sd] median   max
Connect:        0    0   0.3      0       9
Processing:     3   31   6.4     33      52
Waiting:        3   25   6.4     28      47
Total:          4   31   6.4     33      52

Percentage of the requests served within a certain time (ms)
  50%     33
  66%     34
  75%     34
  80%     35
  90%     38
  95%     41
  98%     46
  99%     50
 100%     52 (longest request)</pre>
<p>2736 requests per second on JRuby/Jetty vs 1600 on Ruby/Thin. As noted this isn&#8217;t meaningfully useful, in that it&#8217;s a hello world example and I&#8217;ve not tried to pick the fastest stacks on either side. I&#8217;m more bothered about it not being slower, because the main reason to pursue this approach is simplicity. Having a single self contained artefact that contains all it&#8217;s dependencies including a production web server is very appealing.</p>
<p>I&#8217;m hoping to give this a go with some less trivial applications, and probably more importantly look to compare a production stack based around these self-contained executables vs the dependency chain that is modern Ruby application stacks.</p>
<p>Thanks to <a href="http://blog.nicksieger.com/">Nick Sieger</a> for both writing Warbler and for helping with a few questions on the JRuby mailing list and on Twitter. Thanks also to <a href="https://twitter.com/jabley">James Abley</a> for a few pointers on Java system properties.</p>]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Recent Projects And Talks]]></title>
    <link href="http://www.morethanseven.net/2012/03/31/Recent-projects-and-talks/"/>
    <updated>2012-03-31T00:00:00+01:00</updated>
    <id>http://www.morethanseven.net/2012/03/31/Recent-projects-and-talks</id>
    <content type="html"><![CDATA[<p>I&#8217;ve been pretty busy with all things <a href="https://www.gov.uk"><span class="caps">GOV</span>.UK</a> recently but I&#8217;ve managed to get a few bits of unrelated code up and a few talks in. I&#8217;m <em>still</em> pretty busy so here&#8217;s a list of some of them rather than a proper blog post.</p>
<ul>
	<li><a href="http://www.slideshare.net/garethr/mining-puppet">Puppet Data Mining</a> talk from last weeks PuppetCamp in Edinburgh.</li>
	<li><a href="http://www.slideshare.net/garethr/web-operations">Introducting Web Operations</a> talk I gave at work to give my mainly non-development colleagues an idea about what it&#8217;s all about.</li>
	<li><a href="http://www.slideshare.net/garethr/learnings-from-govuk">Learning from building <span class="caps">GOV</span>.UK</a> talk I gave a month back or so to Cambridge Geek Night. We did an excellent full project retrospective after the beta launch and this lists some of the things we learnt.</li>
</ul>
<p>After someone bugged me on Twitter I realised the small bit of code we&#8217;ve been using for our Nagios dashboard wasn&#8217;t out in the wild. So introducing <a href="https://github.com/garethr/nash">Nash</a>, a very simple high level check dashboard which screenscrapes nagiosand runs happily on Heroku.</p>
<p>Although I&#8217;ve not been writing too much on here I&#8217;ve been keeping <a href="http://devopsweekly.com/">Devops Weekly</a> going each week for over a year now. I&#8217;ve just crossed 3000 subscribers which is pretty neat for a pet project.</p>]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Dashboards At Gov.Uk]]></title>
    <link href="http://www.morethanseven.net/2012/02/19/Dashboards-at-govuk/"/>
    <updated>2012-02-19T00:00:00+00:00</updated>
    <id>http://www.morethanseven.net/2012/02/19/Dashboards-at-govuk</id>
    <content type="html"><![CDATA[<p>This is a bit of a cheat blog post really. I&#8217;ve been crazy busy all month with little time for anything except work (specifically shipping the first release of <a href="https://www.gov.uk/">www.gov.uk</a>). I have had a little time to blog over on the Cabinet Office blog though, about work we&#8217;ve done with dashboards.</p>
<p><a href="http://digital.cabinetoffice.gov.uk/2012/02/08/radiating-information/">http://digital.cabinetoffice.gov.uk/2012/02/08/radiating-information/</a></p>
<p>If you&#8217;re ever looking for good little hack projects dashboards are perfect, and often hugely useful once up and running. Convincing people of this before you have a few in the office might be hard &#8211; so just build something simple in a lunch break and find a screen to put it on. We&#8217;ve had great feedback from ours, both from people wandering through the office and from our colleagues who have a better idea of what&#8217;s going on.</p>]]></content>
  </entry>
  
</feed>
