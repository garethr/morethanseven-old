<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: django | Morethanseven]]></title>
  <link href="http://www.morethanseven.net/tags/django/atom.xml" rel="self"/>
  <link href="http://www.morethanseven.net/"/>
  <updated>2013-12-26T18:51:05+00:00</updated>
  <id>http://www.morethanseven.net/</id>
  <author>
    <name><![CDATA[Gareth Rushgrove]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Django and Rails presentation from QCon]]></title>
    <link href="http://www.morethanseven.net/2013/01/13/django-and-rails-presentation-from-qcon/"/>
    <updated>2013-01-13T16:31:00+00:00</updated>
    <id>http://www.morethanseven.net/2013/01/13/django-and-rails-presentation-from-qcon</id>
    <content type="html"><![CDATA[<p>I had great fun back in November at the "QCon":http://qconsf.com/ conference in San Francisco. As well as currating one of the tracks and catching up with people in the area I managed to give the following talk.</p>

<script async class="speakerdeck-embed" data-id="7e1dd5a03efc0130083b123139173def" data-ratio="1.33333333333333" src="http://www.morethanseven.net//speakerdeck.com/assets/embed.js"></script>


<p>In hindsight it might have been a bit odd to try and cover both Rails and Django examples in the one presentation but it was quite good fun putting together code examples using both of them at the same time. As well as a large set of tips, tricks and tools I settled on a few things that I think any web (or other) framework should support out of the box.</p>

<ul>
<li>A debug toolbar</li>
<li>Transparent caching support</li>
<li>Hooks for instrumentation</li>
<li>Configurable logging</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Django Performance Patterns 1: Measuring Performance]]></title>
    <link href="http://www.morethanseven.net/2011/06/30/Django-performance-1-measuring-performance/"/>
    <updated>2011-06-30T00:00:00+01:00</updated>
    <id>http://www.morethanseven.net/2011/06/30/Django-performance-1-measuring-performance</id>
    <content type="html"><![CDATA[<p>h2. Preface</p>

<p>As Django has matured it's being used for bigger and bigger projects. At the same time it's also being used by more and more people building relatively simple applications quickly. Everyone's application is different, but I'd wager the vast majority of these have a range of common performance problems. Performance is often something only larger teams get to spend time really getting to grips with. This is sometimes because smaller projects can't afford the time, or more often probably that things are thought to be <em>fast enough</em> anyway.</p>

<p>One advantage of using a framework is the sharing of common solutions to common problems that happens as a community forms. In what is hopefully going to be a bit of a series I'm going to cover some simple things everyone can do to improve application performance. The patterns are generally applicable, but I'm going to focus on Django examples.</p>

<p>I'm going to be pretty opinionated about the stack I'm using when necessary. I'm not looking to compare different web servers or databases or python versions. And I'd rather give concrete examples than generalise. If you're using a different stack that's fine, somethings will just work and others will need you to know how to configure the software you've already chosen. I'm also going to focus on a very small and simple to understand application. Most of these techniques scale up just fine, but I feel people don't often use them on smaller projects because they thing you can <em>only</em> use them on larger ones. Or that you won't see much impact on a smaller project. Both of these don't ring true in my opinion and I'll hopefully show why.</p>

<p>h2. Measuring Performance</p>

<p>In this first part of the series lets take a quick detour to frame everything else. Lets talk about ways we can measure performance so we can see if the changes we're making have the desired impact. If you're not measuring performance already then start here.</p>

<p>We'll start out looking at a few tools which are useful when taking a view by view approach to analysing performance. These generally ignore the impact of load on the system but because of this are generally easier to understand and read.</p>

<p>h2. Django Debug Toolbar</p>

<p>Most Django developers will hopefully already be using the excellent "Debug Toolbar":. It has a number of features relevant to our current quest but the most interesting is the query count. Less queries is nearly always better. That's a whopping generalisation, but looking for unnecessary queries or duplicated queries or particularly slow running queries is a great way of making your application faster. The ORM makes it pretty easy to end up with a querysplosion if you're not paying attention.</p>

<p>It's very simple to install:</p>

<pre>pip install django-debug-toolbar</pre>


<p>The query section shows you the number of queries, the individual queries themselves and the time taken. It's designed to be run in debug mode, so the actual query times will likely be lower in production, but the query that's taking ages in development will probably still be slow when you go live.</p>

<p><img src="http://image-host.appspot.com/i/img?id=agppbWFnZS1ob3N0cg0LEgVJbWFnZRiB-gEM" alt="Django debug toolbar"/></p>

<p>h2. YSlow</p>

<p>"YSlow":http://developer.yahoo.com/yslow/ is a browser extension for Firefox and Chrome that gives information and recommendations about a number of mainly HTTP, CSS or javascript issues individual pages might have. It will give you a score as well as suggestions for improvement:</p>

<p><img src="http://image-host.appspot.com/i/img?id=agppbWFnZS1ob3N0cg0LEgVJbWFnZRiC-gEM" alt="YSlow showing a score of 96"/></p>

<p>Also useful is the break down of the number of HTTP requests, and the affect of a primed cache on page loading.</p>

<p><img src="http://image-host.appspot.com/i/img?id=agppbWFnZS1ob3N0cg0LEgVJbWFnZRjpgQIM" alt="YSlow showing http request breakdown"></p>

<p>h2. Profiling Middleware</p>

<p>Sometimes you want to know the very low level calls that go into making a page render. For this you'll want to look at profiling tools. The Django wiki has a "useful page on profiling":https://code.djangoproject.com/wiki/ProfilingDjango which is good if dispiriting reading.</p>

<p>Django Snippets has several profiling middleware, one of which is packaged up in the excellent "Django Snippetscream":http://pypi.python.org/pypi/django-snippetscream. We can install that like so:</p>

<pre>pip install django-snippetscream</pre>


<p>Just include the middleware in your debug environment:</p>

<pre>MIDDLEWARE_CLASSES = MIDDLEWARE_CLASSES + ('snippetscream.ProfileMiddleware',)</pre>


<p>You can then append ?prof to any of your URLs and instead of seeing the view you'll see something like the following:</p>

<p><img src="http://image-host.appspot.com/i/img?id=agppbWFnZS1ob3N0cg0LEgVJbWFnZRjRiQIM" alt="Profiling view"/></p>

<p>Look at where your code spends it's time and whether you have repeated calls to the same methods and functions. Sometimes getting down to this level of detail is the easiest way of finding the bottleneck in your application.</p>

<p>h2. Nginx Logging</p>

<p>Here's the first time I'm being opinionated about the stack, by choosing Nginx as my frontend server. I'll talk a little about why this is a good idea later, but for the moment lets concentrate on why this is useful for measuring performance.</p>

<p>Log files are wonderful things, and Nginx has quite a powerful syntax for "adding extra information to log files":http://wiki.nginx.org/HttpLogModule. Note the last line in the definition below.</p>

<pre>log_format timed_combined '$remote_addr - $remote_user [$time_local]  '
      '"$request" $status $body_bytes_sent '
      '"$http_referer" "$http_user_agent" '
      '$request_time $upstream_response_time $gzip_ratio';</pre>


<p>We are adding the entire request time, the time taken by the upstream server (in my case gunicorn) to respond and also the gzip ratio. This is really handy if you're optimising an application already in production. By collecting this data here it's easy to then analyse the logs and pull out things like slow urls or assets not being gzipped effectively.</p>

<p>h2. Django Timelog</p>

<p>Very similar to the above nginx logging, but implemented as a django 1.3 application (so it can be used in development as well) is one of my projects, "django-timelog":https://github.com/garethr/django-timelog. As well as logging the time taken for each request, django-timelog provides a management command to analyse the resulting log file. It produces output which can show in aggregate the average response time of either views or individual URLs.</p>

<pre>
+--------------------------+--------+--------+-------+---------+---------+-------+-------+
| view                     | method | status | count | minimum | maximum | mean  | stdev |
+--------------------------+--------+--------+-------+---------+---------+-------+-------+
| boxes.viewsBoxDetailView | GET    | 200    | 9430  | 0.14    | 0.28    | 0.21  | 0.070 |
+--------------------------+--------+--------+-------+---------+---------+-------+-------+
| boxes.viewsBoxListView   | GET    | 200    | 66010 | 0.17    | 0.28    | 0.232 | 0.045 |
+--------------------------+--------+--------+-------+---------+---------+-------+-------+
| django.views.staticserve | GET    | 200    | 61295 | 0.00    | 0.02    | 0.007 | 0.006 |
+--------------------------+--------+--------+-------+---------+---------+-------+-------+
</pre>


<p>It's packaged so installation should be straightforward.</p>

<pre>pip install django-timelog</pre>


<p>Again this can be used in a production environment, or it can be used locally while developing. You can also use load testing tools as described in a moment to generate traffic which is then logged.</p>

<p>h2. Load Testing</p>

<p>I'm mainly looking for a tool here which can easily generate HTTP traffic in volume, sending a decent number of concurrent requests against your application and returning some useful results. I mainly turn to ab ("Apache bench":http://httpd.apache.org/docs/2.0/programs/ab.html) because it's available everywhere and it's very simple to use.</p>

<p>For example lets hit a site with 100 requests, with requests being sent in batches of 5.</p>

<pre>ab -c 5 -n 100 http://www.vagrantbox.es/12/</pre>


<p>This will print something like the following. For our purposes we're mainly interested in the requests per second value and the mean request time.</p>

<pre>Concurrency Level:      5
Time taken for tests:   1.981 seconds
Complete requests:      100
Failed requests:        0
Write errors:           0
Total transferred:      328300 bytes
HTML transferred:       297400 bytes
Requests per second:    50.47 [#/sec] (mean)
Time per request:       99.064 [ms] (mean)
Time per request:       19.813 [ms] (mean, across all concurrent requests)
Transfer rate:          161.82 [Kbytes/sec] received</pre>


<p>Load testing is a pretty large topic. For instance even with the above simple example how do we know if 100 requests is enough? (it's not.) Or whether a concurrency of 5 is useful? Often what you're interested in is where your application starts to saturate or where it starts to error. But even without getting bogged down in the details a simple test like this can show changes have had a positive or negative effect. I'll show examples of this as we investigate optimisation techniques.</p>

<p>If you're working on a larger project hopefully you'll have the time to investigate other approaches too. I'm quite a fan of using production logs to replay requests for instance, and of using "Funkload":http://funkload.nuxeo.org/ for running scenarios under load. I'll hopefully write more about those later. I've heard good things about "Tsung":http://tsung.erlang-projects.org/ as well, "HTTPerf":http://www.hpl.hp.com/research/linux/httperf/ is excellent and "JMeter":http://jakarta.apache.org/jmeter/ has many fans. I'm using ab for examples because it's point and shoot and you probably already have it installed without knowing.</p>

<p>Hopefully that's a useful list of tools to get a baseline of where you're at with performance. The rest of the articles in this series will show approaches to improve performance, and come back to one or more of these tools to confirm we're heading in the right direction.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Logging Django Performance]]></title>
    <link href="http://www.morethanseven.net/2011/06/09/Logging-django-performance/"/>
    <updated>2011-06-09T00:00:00+01:00</updated>
    <id>http://www.morethanseven.net/2011/06/09/Logging-django-performance</id>
    <content type="html"><![CDATA[<p>I've been doing some basic performance profiling work with Ruby on Rails recently and one tool I found very useful was the "request log analyzer":https://github.com/wvanbergen/request-log-analyzer. It's a relatively simple command line application that you can point at the Rails application log files and it outputs lots of information in agregate. So information about request duration averages or about SQL queries run. When working on a recent Django project I wanted a tool to do the same thing and ended up writing timelog.</p>

<p>I did a bit of research to see if I could find something similar. Here are a few other interesting tools that didn't quite do what I wanted:</p>

<ul>
<li>"Django Slow Log":https://github.com/jmoiron/django-slow-log - This logs things like memory and load averages</li>
<li>"Django Dump Slow":https://github.com/lamby/django-dumpslow - Similar but designed to just log slow requests rather than everything, also needs a Redis backend</li>
<li>"Zamboni Middleware":https://github.com/jbalogh/zamboni/blob/master/apps/amo/middleware.py#L162 - This is very similar to what I wanted, but it's not a separate module and I didn't find anything to analyse the results</li>
</ul>


<p>Timelog is very similar to the middleware in Zamboni, the only real difference being I'm using the new logging support in Django 1.3. More interesting is the bundled management command which will output something like:</p>

<pre>
+--------------------------+--------+--------+-------+---------+---------+-------+-----------------+
| view                     | method | status | count | minimum | maximum | mean  | stdev           |
+--------------------------+--------+--------+-------+---------+---------+-------+-----------------+
| boxes.viewsBoxDetailView | GET    | 200    | 9430  | 0.14    | 0.28    | 0.21  | 0.0700037118541 |
+--------------------------+--------+--------+-------+---------+---------+-------+-----------------+
| boxes.viewsBoxListView   | GET    | 200    | 66010 | 0.17    | 0.28    | 0.232 | 0.0455415351076 |
+--------------------------+--------+--------+-------+---------+---------+-------+-----------------+
| django.views.staticserve | GET    | 200    | 61295 | 0.00    | 0.02    | 0.007 | 0.0060574669888 |
+--------------------------+--------+--------+-------+---------+---------+-------+-----------------+
</pre>


<p>At the moment I've not done any real benchmarking or optimisation of the script, but it will chew through a 300,000 line (20MB) log file in under 20s on my aging macbook.</p>

<p>The code for Timelog is on github at "github.com/garethr/django-timelog":http://github.com/garethr/django-timelog and I've uploaded to PyPi as well at "pypi.com/django-timelog":http://pypi.python.org/pypi/django-timelog. You can install it with the usual tools like pip:</p>

<pre>pip install django-timelog</pre>


<p>Once installed you need to do a little configuration to get things working. First add the middleware to your MIDDLEWARE_CLASSES in your settings file.</p>

<pre>
MIDDLEWARE_CLASSES = (
  'timelog.middleware.TimeLogMiddleware',
</pre>


<p>Next add timelog to your INSTALLED_APPS list. This is purely for the management command discovery.</p>

<pre>
INSTALLED_APPS = (
  'timelog',
</pre>


<p>Then configure the logger you want to use. This really depends on what you want to do, the django 1.3 logging setup is pretty powerful. Here's how I've got logging setup as an example:</p>

<pre>
TIMELOG_LOG = '/path/to/logs/timelog.log'

LOGGING = {
  'version': 1,
  'formatters': {
    'plain': {
      'format': '%(asctime)s %(message)s'},
    },
  'handlers': {
    'timelog': {
      'level': 'DEBUG',
      'class': 'logging.handlers.RotatingFileHandler',
      'filename': TIMELOG_LOG,
      'maxBytes': 1024 * 1024 * 5,  # 5 MB
      'backupCount': 5,
      'formatter': 'plain',
    },
  },
  'loggers': {
    'timelog.middleware': {
      'handlers': ['timelog'],
      'level': 'DEBUG',
      'propogate': False,
     }
  }
}
</pre>


<p>In order for the analyser script to work correctly you'll need to use the plain formatter and to register a handler for the timelog.middleware logger.</p>

<p>With that all configured try hitting your application a few times. You should see a log file created at the location specified in TIMELOG_LOG. Fill that up with a few lines and then run the analyze_timelog management command:</p>

<pre>python manage.py analyze_timelog</pre>


<p>This should output something similar to the above table but with your timings and views. The management command currently allows you to point the analyzer at a different file say from a backup, or a file you've pulled down from production but want to run the command locally. I'll likely add some filters as time permits for things like not showing all views or showing only views between a given date range.</p>

<p>The above table showing the view function is good for big picture trends, but if you want to dig down into a particular path then you can pass an argument to not reverse the path:</p>

<pre>python manage.py analyze_timelog --noreverse</pre>


<p>This should give you something more like:</p>

<pre>
+----------------------------------+--------+--------+-------+---------+---------+-------+------------------+
| view                             | method | status | count | minimum | maximum | mean  | stdev            |
+----------------------------------+--------+--------+-------+---------+---------+-------+------------------+
| /assets/css/main.css             | GET    | 200    | 61295 | 0.00    | 0.02    | 0.007 | 0.0060574669888  |
+----------------------------------+--------+--------+-------+---------+---------+-------+------------------+
| / bob                            | GET    | 404    | 4715  | 0.01    | 0.01    | 0.01  | 0.0              |
+----------------------------------+--------+--------+-------+---------+---------+-------+------------------+
| /                                | GET    | 200    | 66010 | 0.17    | 0.28    | 0.232 | 0.0455415351076  |
+----------------------------------+--------+--------+-------+---------+---------+-------+------------------+
| /__debug__/m/css/toolbar.min.css | GET    | 304    | 4715  | 0.00    | 0.00    | 0.0   | 0.0              |
+----------------------------------+--------+--------+-------+---------+---------+-------+------------------+
| /14/                             | GET    | 200    | 9430  | 0.14    | 0.28    | 0.21  | 0.0700037118541  |
+----------------------------------+--------+--------+-------+---------+---------+-------+------------------+
</pre>



]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[A Continuous Deployment Example Setup]]></title>
    <link href="http://www.morethanseven.net/2011/03/20/A-continuous-deployment-example-setup/"/>
    <updated>2011-03-20T00:00:00+00:00</updated>
    <id>http://www.morethanseven.net/2011/03/20/A-continuous-deployment-example-setup</id>
    <content type="html"><![CDATA[<p>One of the reasons behind getting around to building "Vagrantbox.es":http://www.vagrantbox.es recently was I was giving a talk to a group of startups on "The Difference Engine":http://thedifferenceengine.eu/ programme and I wanted to have an example project to demonstrate various things. I wanted to demonstrate everything from sensible version control habbits, configuration management, basic orcestration and most importantly a solid deployment process. I've decided to write up what I'm doing for deployment because I think it's pretty nice, and for all the talk about Continuous Deployment I haven't seen many examples of code and configuration to make it happen.</p>

<p>Most of what I'll cover is pretty easy to map to whatever technologies your using. For this project I'd gone for Git, Django, Gunicorn, Nginx, Fabric, Mysql and Jenkins and I'm deploying to Ubuntu running on "Brightbox Cloud":http://www.brightbox.co.uk/. Apart from the Jenkins instance in the middle you could follow the instructions and swap things out easily.</p>

<p>h2. Jenkins</p>

<p>First up lets install "Jenkins":http://jenkins-ci.org/. I setup a separate cloud instance just to run the Continuous Integration server. I find this approach easier to manage but you could always run this locally if you prefer. The Jenkins folk provide very up to date "packages for Debian":http://pkg.jenkins-ci.org/debian/ so I chose to use those.</p>

<p>h3. Plugins</p>

<p>Jenkins provides a huge number of optional plugins which enable various additional features. Plugins are installed via the web interface at /pluginManager. I've installed:</p>

<ul>
<li>"Jenkins Cobertura Plugin":http://wiki.jenkins-ci.org/display/JENKINS/Cobertura+Plugin</li>
<li>"Jenkins GIT plugin":http://wiki.jenkins-ci.org/display/JENKINS/Git+Plugin</li>
<li>"GitHub plugin":http://wiki.jenkins-ci.org/display/JENKINS/Github+Plugin</li>
<li>"Green Balls":http://wiki.hudson-ci.org/display/HUDSON/Green+Balls</li>
<li>"Hudson Violations plugin":http://wiki.hudson-ci.org/display/HUDSON/Violations</li>
</ul>


<p>Only the Git plugin is really required for what I'm doing with deployment. Cobertura and Violations are code quality metrics tools that I use to record output from pylint and code coverage for my test suite.</p>

<p>h2. The Source</p>

<p>My finished project was already on GitHub in a private repository. I'm using a requirements.txt file to record python dependencies so I can use pip to install them automatically and I'm using Virtualenv to sandbox this installation. I'm also using South to manage my database schema changes. I won't go into that here as it's pretty Python specific, Rails for instance has Active Record migrations, RVM and Bundler which do pretty much the same job. PHP has PEAR and some of the frameworks offer a migration tool.</p>

<p>I then created two projects in Jenkins:</p>

<p><img src="http://image-host.appspot.com/i/img?id=agppbWFnZS1ob3N0cg0LEgVJbWFnZRiRywEM" alt="Jenkins dashboard"/></p>

<p>h3. Project 1: Vagrantboxes</p>

<p>This is the main build of my master branch in Git. As well as setting up the Git repo as shown below I've set a polling schedule to */5 * * * * (that's every 5 minutes) and also set Trigger builds remotely so I can have a task in my fabfile which triggers a build immediately.</p>

<p><img src="http://image-host.appspot.com/i/img?id=agppbWFnZS1ob3N0cg0LEgVJbWFnZRjh2gEM" alt="Git config for Jenkins"/></p>

<p>I then have two build steps, both of which execute shell commands. The first installs any new requirements via pip:</p>

<pre>bash -l -c "source bin/activate; pip install -r requirements.txt"</pre>


<p>The second runs my test suite and generates the XML output required to show the test results in Jenkins:</p>

<pre>bash -l -c "source bin/activate; cd vagrantboxes/configs/common; python manage.py jenkins boxes"</pre>


<p>I'm using the rather handy "Django Jenkins":https://github.com/kmmbvnr/django-jenkins application for this.</p>

<p>So far so good. This gives us a project that, when we push some changes to GitHub, will pull those changes down to the CI server and run our test suite, giving us feedback as to whether the tests pass or fail.</p>

<p>Now for the trick, in Post-build Actions tick Build other projects and specify the name of another project that we'll setup next. Mine is called Vagrantboxes-deploy.</p>

<p><img src="http://image-host.appspot.com/i/img?id=agppbWFnZS1ob3N0cg0LEgVJbWFnZRirwwEM" alt="Post build action in Jenkins"/></p>

<p>h3. Project 2: Vagrantboxes-deploy</p>

<p>This project is triggered only when the previous project runs successfully. And all it's going to do is run the deployment script on the project we just built. The setup for this project is very simply, it has one build step which just executes the following:</p>

<pre>bash -l -c "cd /var/lib/jenkins/jobs/Vagrantboxes/workspace; source bin/activate; fab appserver deploy"</pre>


<p>The specifics of the Fabric script here aren't that important but I'm doing something not too disimilar to "what I described here":http://morethanseven.net/2009/07/27/fabric-django-git-apache-mod_wsgi-virtualenv-and-p.html.</p>

<p>The reason I've setup a separate project for these is so I can, if I choose, trigger a deployment separately to the full build, and also so I can very easily disable deployments even if the main build is still running.</p>

<p>h2. Conclusions</p>

<p>With this setup whenever I push code to master it triggers a build. If the test suite passes it runs the deployment script and pushes out the code to the live web servers. This suites me and this project but you might find it easier to start by pushing all successfull builds out to a staging environment. And maybe then moving on to having a new project which is only triggered manually for deploying to production.</p>

<p><img src="http://image-host.appspot.com/i/img?id=agppbWFnZS1ob3N0cg0LEgVJbWFnZRiqwwEM" alt="project view in Jenkins"/></p>

<p>This setup has other advantages too. The Jenkins dashboard becomes a handy tool for recording deployment events. You can easily setup emails or IM messages or Campfire posts to alert other team members whenever a deployment happens. And it really really makes sure your delployment scripts work without hand holding.</p>

<p>This is a simple project that I'm working on on my own, but in a team environment you'd likely have a more complex branching strategy and more Jenkins projects. You might also introduce some gateways for manual testing but the starting point is the same. Jenkins makes archiving successful build artifacts relatively easy as well, this setup has a few race condition possibilities that you can fix by building artifacts from successful builds. Jenkins also supports building from different branches and having different branches trigger different projects, all handy if you want to grow this kind of setup.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Python: What To Use?]]></title>
    <link href="http://www.morethanseven.net/2010/06/29/Python-what-to-use/"/>
    <updated>2010-06-29T00:00:00+01:00</updated>
    <id>http://www.morethanseven.net/2010/06/29/Python-what-to-use</id>
    <content type="html"><![CDATA[<p>My friend "Jamie Rumbelow":http://jamieonsoftware.com has started a new project and decided to use Python. He asked a great question over on "Stack Overflow":http://stackoverflow.com/questions/3143115/architecting-from-scratch-in-python-what-to-use which basically came down to <em>what should I use for my first proper Python web application project</em>. After a quick prompting on twitter I decided to have a go. I've cross posted my anwser below more because it took as long as a typical blog post to write.</p>

<p>h2. Frameworks</p>

<p>OK, so I'm a little biased here as I currently make extensive use of Django and organise the Django User Group in London so bear that in mind when reading the following.</p>

<p>Start with Django because it's a great gateway drug. Lots of documentation and literature, a very active community of people to talk to and lots of example code around the web.</p>

<p>That's a completely non-technical reason. Pylons is probably purer in terms of Python philosophy (being much more a collection of discrete bits and pieces) but lots of the technical stuff is personal preference, at least until you get into Python more. Compare the very active Django tag on Stack Overflow with that of pylons or turbogears though and I'd argue getting started is simply easier with Django irrespective of anything to do with code.</p>

<p>Personally I default to Django, but find that an increasing amount of time I actually opt for writing using simpler micro frameworks (think Sinatra rather than Rails). Lots of things to choose from ("good list here":http://fewagainstmany.com/blog/python-micro-frameworks-are-all-the-rage). I tend to use MNML (because I wrote parts of it and it's tiny) but others are actively developed. I tend to do this for small, stupid web services which are then strung together with a Django project in the middle serving people.</p>

<p>Worth noting here is appengine. You have to work within it's limitations and it's not designed for everything but it's a great way to just play with Python and get something up and working quickly. It makes a great testbed for learning and experimentation.</p>

<p>h2. Mongo/ORM</p>

<p>On the MongoDB front you'll likely want to look at the "basic python mongo library":http://api.mongodb.org/python/ first to see if it has everything you need. If you really do want something a little more ORM like then "mongoengine":http://hmarr.com/mongoengine/ might be what you're looking for. A bunch of folks are also working on making Django specifically integrate more seamlessly with nosql backends. Some of that is for future Django releases, but "django-norel":http://www.allbuttonspressed.com/projects/django-nonrel has code now.</p>

<p>For relational data "SQLAlchemy":http://www.sqlalchemy.org/ is good if you want something standalone. Django's ORM is also excellent if you're using Django.</p>

<p>h2. API</p>

<p>The most official Oauth library is "python-oauth2":http://github.com/simplegeo/python-oauth2, which handily has a Django example as part of it's docs.</p>

<p>"Piston":http://bitbucket.org/jespern/django-piston/wiki/Home is a Django app which provides lots of tools for building APIs. It has the advantage of being pretty active and well maintained and in production all over the place. Other projects exist too, including "Dagny":http://zacharyvoase.github.com/dagny/ which is an early attempt to create something akin to RESTful resources in Rails.</p>

<p>In reality any Python framework (or even just raw WSGI code) should be reasonably good for this sort of task.</p>

<p>h2. Testing</p>

<p>Python has unittest as part of it's standard library, and unittest2 is in python 2.7 (but "backported to previous versions too":http://pypi.python.org/pypi/unittest2/0.1.4). Some people also like "Nose":http://code.google.com/p/python-nose/, which is an alternative test runner with some additional features. "Twill":http://twill.idyll.org/ is also nice, it's a "a simple scripting language for Web browsing", so handy for some functional testing. "Freshen":http://github.com/rlisagor/freshen is a port of cucumber to Python. I haven't yet gotten round to using this in anger, but a quick look now suggests it's much better than when I last looked.</p>

<p>I actually also use Ruby for high level testing of Python apps and apis because I love the combination of celerity and cucumber. But I'm weird and get funny looks from other Python people for this.</p>

<p>h2. Message Queues</p>

<p>For a message queue, whatever language I'm using, I now always use RabbitMQ. I've had some success with stompserver in the past but Rabbit is awesome. Don't worry that it's not itself written in Python, neither is PostgresSQL, Nginx or MongoDB - all for good reason. What you care about are the libraries available. What you're looking for here is "py-amqplib":http://barryp.org/software/py-amqplib/ which is a low level library for talking amqp (the protocol for talking to rabbit as well as other message queues). I've also used "Carrot":http://github.com/ask/carrot/, which is easier to get started with and provides a nicer API. Think bunny in Ruby if you're familiar with that.</p>

<p>h2. Environment</p>

<p>Whatever bits and pieces you decide to use from the Python ecosystem I'd recommend getting to who "pip and virtualenv":http://clemesha.org/blog/2009/jul/05/modern-python-hacker-tools-virtualenv-fabric-pip/ - note that fabric is also cool, but not essential and these docs are out of date on that tool). Think about using Ruby without gem, bundler or rvm and you'll be in the right direction.</p>
]]></content>
  </entry>
  
</feed>
