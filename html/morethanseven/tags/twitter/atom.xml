<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: twitter | Morethanseven]]></title>
  <link href="http://www.morethanseven.net/tags/twitter/atom.xml" rel="self"/>
  <link href="http://www.morethanseven.net/"/>
  <updated>2014-04-25T12:05:21+02:00</updated>
  <id>http://www.morethanseven.net/</id>
  <author>
    <name><![CDATA[Gareth Rushgrove]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Devops Twitter Aggregator]]></title>
    <link href="http://www.morethanseven.net/2010/05/26/Devops-twitter-aggregator/"/>
    <updated>2010-05-26T00:00:00+02:00</updated>
    <id>http://www.morethanseven.net/2010/05/26/Devops-twitter-aggregator</id>
    <content type="html"><![CDATA[<p>I've been hacking on appengine again and have thrown up a simple "twitter aggregator for devops":http://devopstweets.appspot.com/. It's again based on "TwitterEngine":http://github.com/steffentchr/twitterengine with an increasing number of additions and changes.</p>

<p>As well as just the tweets I want to build a few other small features. The first of which is link extraction, so at the moment you'll see recent links a the top of the page. I'll hopefully make that a little more useful, with better browing and converting short urls into the real ones. I also have vague plans for providing exports, listing people talking about devops and some useful graphs to track general activity around devops.</p>

<p><notextile>
<img src="http://image-host.appspot.com/i/img?id=agppbWFnZS1ob3N0cg0LEgVJbWFnZRjphAEM" alt="Devops aggregator on Twitter"
</notextile></p>

<p>I'm really interested to see if the whole discussion around the term devops grows over the next year or so, and I'm hoping this will make it a little easier to see that change happen.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Mixing it Up - Programming Language Choice]]></title>
    <link href="http://www.morethanseven.net/2009/04/04/mixing-it-programming-language-choice/"/>
    <updated>2009-04-04T00:00:00+02:00</updated>
    <id>http://www.morethanseven.net/2009/04/04/mixing-it-programming-language-choice</id>
    <content type="html"><![CDATA[<p>So the "Register article about Twitter":http://www.theregister.co.uk/2009/04/01/twitter_on_scala/ seems to have kicked over yet another Ruby/Rails doesn't scale debate - mainly it seems from people who haven't read any of the back story or the real meat of the story. For anyone catching up I'd suggest reading "this recent interview":http://www.artima.com/scalazine/articles/twitter_on_scala.html with three of the Twitter developers. Ikai Lan made some particular good points about "people who don't RTFM":http://ikaisays.com/2009/04/02/twitter-ruby-on-rails-scala-and-people-who-dont-rtfa/ and the comments are well worth reading too. Tony Arcieri, of "Reia":http://wiki.reia-lang.org/ fame, took another approach and wondered why "non of the open source message queues every got a look in":http://unlimitednovelty.com/2009/04/twitter-blaming-ruby-for-their-mistakes.html</p>

<p>What it really all comes down to is that Twitter are using more than one language to write their systems in. What I don't understand is why this is a shock to anyone, or why it's a bad think? Google appear to use Java and Python for most things. Yahoo! use Java and PHP (and C and Perl I think?). Microsoft use VB and C/C++/C# and probably F#. At work we use .NET and Python for different things.</p>

<p>Big companies have been using multiple languages and platforms for good and bad reasons for ever. Sometimes it's about legacy systems, but often it's about using the right tool for the job. I think lots of people jumping in on the debate do so from a point of view that everyone uses one language for everything, mainly because most personal projects or small agency style jobs do just that. Why overcomplicate smaller projects with the need for people to know more than one language? In a small general purpose team it's also going to make recruiting and getting people up to speed much harder.</p>

<p>But for startups doing interesting things it's potentially both more efficient and more interesting to use multiple platforms. I think Dopplr might be mainly Ruby with a smattering of Erlang, all built around an ApacheMQ message queue, and "Matt":http://www.hackdiary.com/ has talked about that architecture at various conferences without being called out on it.</p>

<p>So for your next personal project why not pick a handy message queue (personally I like "RabbitMQ":http://www.rabbitmq.com/ and "StompServer":http://stompserver.rubyforge.org/), and at least two complimentary languages and see how it changes the architecture of what you build? Mix PHP with an Erlang backend or go for Twitters Ruby/Scala mix. It might very well be overkill for that blog or todo list application you had in mind, but it just might  teach you more about picking the right tools for the job when you come across non-trivial problems.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Archiving Twitter data with Python]]></title>
    <link href="http://www.morethanseven.net/2007/11/23/archiving-twitter-data-with-python/"/>
    <updated>2007-11-23T00:00:00+01:00</updated>
    <id>http://www.morethanseven.net/2007/11/23/archiving-twitter-data-with-python</id>
    <content type="html"><![CDATA[<p>"Alex":http://www.al3x.net/ from "Twitter":http://twitter.com just got round to adding the ability to export your entire archive of tweets via the "API":http://groups.google.com/group/twitter-development-talk/web/api-documentation. A few people on the mailing list had been asking for this for a while so good to see it get released.</p>

<p>I couldn't resist knocking together a very quick and simple Python script to go off and get all your tweets, presented here for anyone else to play around with. Note that simple, fast and works on my machine were watchwords here. Don't expect fancy parameters, much error handling or artificial intelligence.</p>

<p><notextile>
&lt;% syntax_colorize :python, type=:coderay do %>
import urllib2
username = '<YOUR USERNAME>'
password = '<YOUR PASSWORD>'
format = 'json' # json or xml
filename = 'archive.json' # filename of the archive
tweets = 164 # number of tweets
pages = (int(float(tweets)/float(80)))+1
auth = urllib2.HTTPPasswordMgrWithDefaultRealm()
auth.add_password(None, 'http://twitter.com/account/', username, password)
authHandler = urllib2.HTTPBasicAuthHandler(auth)
opener = urllib2.build_opener(authHandler)
urllib2.install_opener(opener)
i = 1
response = ''
print 'Downloading tweets. Note that this may take some time'
while i &lt;= pages:</p>

<pre><code>request = urllib2.Request('http://twitter.com/statuses/user_timeline/account.' \
+ format + '?page=' + str(i))
response = response + urllib2.urlopen(request).read()
i = i + 1
</code></pre>

<p>handle = open(filename,"w")
handle.write(response)
handle.close()
print 'Archived ' + str(tweets) + ' of ' + username + \
'\'s tweets to ' + filename
&lt;% end %>
</notextile></p>

<p>The main thing to note here though is the ideal of "data portability":http://www.dataportability.org/. Let's just say I wanted to move to Jaiku or Pownce instead of Twitter, but didn't want to lose all that data. If I can knock up an export script in half an hour then all you need are import data API calls and a little more scripting.</p>

<p>As it is, I'm more interesting in seeing what I can do with my data now I can get at it. "Brian":http://suda.co.uk just suggested a "quick visualisation tool":http://simile.mit.edu/timeline/ (which already eats JSON) and I'd already been thinking about "language analysis":http://morethanseven.net/posts/pygunfog/ and maybe having a look at "APML":http://www.apml.org/ some more. Open data is simply more fun.</p>
]]></content>
  </entry>
  
</feed>
